# --- Switch between providers ---
# true  = use Ollama (local model, e.g., phi or mistral)
# false = use OpenAI (cloud model)
USE_OLLAMA=false

# --- Ollama config ---
OLLAMA_MODEL=phi

# --- OpenAI config ---
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
